# -*- coding: utf-8 -*-
"""
Created on Sat Mar 14 11:44:51 2020

@author: B치lint
"""

# -*- coding: utf-8 -*-
"""
Created on Sat Mar 14 10:02:44 2020

@author: B치lint
"""
import numpy as np
import pandas as pd
import pickle
from sklearn.neural_network import MLPRegressor




# load data
filterlist = np.array(['softskill01', 'softskill02',
                       'softskill03', 'softskill04',
                       'softskill05', 'softskill06',
                       'softskill07', 'softskill08',
                       'softskill09', 'softskill10',
                       'softskill11', 'softskill12',
                       'softskill13', 'softskill14',
                       'softskill15'  'softskill16',])

"""
# I just listed these here, its handy when u see all vavriaable names

['softskill01', 
'softskill02',
'softskill03', 
'softskill04',
'softskill05', 
'softskill06',
'softskill07'(15)*, 
'softskill08',
'softskill09', 
'softskill10',
'softskill11', 
'softskill12',
'softskill13'(15)*, 
'softskill14'(25!)*,
'softskill15'  
'softskill16,]

"""


filter_no=0
r2 =np.array([]) 


# train

for i in range(16):   # 16, because 16 different softskill dimiension we have
    data = pd.read_csv('apitest_all.csv', decimal=',', delimiter=';') 
    name_filter = filterlist[filter_no]
    data = data.loc[data['name'] == name_filter]
    if name_filter == 'softskill07': # we do this to filter out filters, wich has more than 10 rows
        training_amount = int(0.9 * len(data))  # 90% training and validation, 10% test
        training_data = data[:training_amount]  # and validation data
        test_data = data[training_amount:]
        regr = MLPRegressor(hidden_layer_sizes=300, learning_rate='adaptive') 
        X = np.array(training_data[[f'answer_num_{n}' for n in range(1, 16)]]) # this one has 15 rows
        y = np.array(training_data['result'])
        model = regr.fit(X, y)
        
        # now evaluate the model with R^2
        Xtest = np.array(test_data[[f'answer_num_{n}' for n in range(1, 16)]])
        ytest = np.array(test_data['result'])
        print('R^2 score of the trained model ' + name_filter + ' : ', model.score(Xtest, ytest))
        r2 =np.array(r2,[model.score(Xtest, ytest),name_filter]) 
        
    elif name_filter == 'softskill13':
        training_amount = int(0.9 * len(data))  # 90% training and validation, 10% test
        training_data = data[:training_amount]  # and validation data
        test_data = data[training_amount:]
        regr = MLPRegressor(hidden_layer_sizes=300, learning_rate='adaptive')
        X = np.array(training_data[[f'answer_num_{n}' for n in range(1, 16)]]) # this one has 15 rows
        y = np.array(training_data['result'])
        r2 =np.array(r2,[model.score(Xtest, ytest)]) 
      
        # now evaluate the model with R^2
        Xtest = np.array(test_data[[f'answer_num_{n}' for n in range(1, 16)]])
        ytest = np.array(test_data['result'])
        print('R^2 score of the trained model ' + name_filter + ' : ', model.score(Xtest, ytest))
        r2 =np.array(r2 ![model.score(Xtest, ytest),name_filter]) 

        
    elif name_filter == 'Kultur치lis nyitotts치g':
        training_amount = int(0.9 * len(data))  # 90% training and validation, 10% test
        training_data = data[:training_amount]  # and validation data
        test_data = data[training_amount:]
        regr = MLPRegressor(hidden_layer_sizes=300, learning_rate='adaptive')
        X = np.array(training_data[[f'answer_num_{n}' for n in range(1, 31)]]) # this one has 30 rows
        y = np.array(training_data['result'])
        r2 =np.array(r2,[model.score(Xtest, ytest)]) 
        
        # now evaluate the model with R^2
        Xtest = np.array(test_data[[f'answer_num_{n}' for n in range(1, 31)]])
        ytest = np.array(test_data['result'])
        print('R^2 score of the trained model ' + name_filter + ' : ', model.score(Xtest, ytest))
        r2 =np.array(r2,[model.score(Xtest, ytest),name_filter]) 
   
    else: # all the others has 10 rows
        training_amount = int(0.9 * len(data))  # 90% training and validation, 10% test
        training_data = data[:training_amount]  # and validation data
        test_data = data[training_amount:]
        regr = MLPRegressor(hidden_layer_sizes=300, learning_rate='adaptive')
        X = np.array(training_data[[f'answer_num_{n}' for n in range(1, 11)]])
        y = np.array(training_data['result'])
        model = regr.fit(X, y)

        # now evaluate the model with R^2
        Xtest = np.array(test_data[[f'answer_num_{n}' for n in range(1, 11)]])
        ytest = np.array(test_data['result'])
        print('R^2 score of the trained model ' + name_filter + ' : ', model.score(Xtest, ytest))
        r2 =np.array([model.score(Xtest, ytest)]) 


# save model - each name filter has a separate model
    pickle.dump(model, open(f'{name_filter}_model.pickle', 'wb'))
    
    
    
    
# saving txt-s for JS porter
    from sklearn_porter import Porter
    porter = Porter(regr, language='js')
    output = porter.export()
    print(output)
    file = open("{name_filter}JS.txt","w")
    file.write(output)
    file.close()
    
    filter_no=filter_no + 1
    
    
# ______________________________________________________
# example on how to run it after training
# load model back (later when used)
    model = pickle.load(open(f'{name_filter}_model.pickle', 'rb'))
    
# predict
answers = [6, 6, 6, 6, 6, 1, 2, 3, 5, 2,6, 6, 6, 6, 6, 1, 2, 3, 5, 2,6, 6, 6, 6, 6, 1, 2, 3, 5, 2,]  # from answer_num_1 to _10
X = np.expand_dims(np.array(answers), axis=0)  # size: nsamples x 10, here nsamples=1
prediction = model.predict(X)

print('input:', answers)
print('prediction:', prediction) 
